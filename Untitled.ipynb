{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stock-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "homeless-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('projects_links.json') as file:\n",
    "  linkinghost = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "greatest-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('project_data.json') as file:\n",
    "  host = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seeing-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostList = []\n",
    "chostList = []\n",
    "linkinghostList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "close-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitPID(val):\n",
    "    valhost = val.split(\"?\")\n",
    "    idhost = valhost[1].split(\"=\")\n",
    "    pureid = idhost[1]\n",
    "    return pureid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "infrared-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSpecialChar(val):\n",
    "    pureval = val.replace(\"\\r\", \"\").replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    return pureval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "southwest-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSpecialCharAndSpace(val):\n",
    "    pureval = val.replace(\"\\r\", \"\").replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\" \", \"\")\n",
    "    return pureval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "competitive-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(passval, name):\n",
    "    with open(name, 'w') as outfile:\n",
    "        json.dump(passval, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "steady-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting project_html to json objects\n",
    "def getPHTML(val, idval):\n",
    "    summary = {}    \n",
    "# #     inserting Pid value to summary\n",
    "    summary['Pid']=idval\n",
    "    \n",
    "# #     processing project summary information\n",
    "    psumHeads = []\n",
    "    psumVals = []\n",
    "    psumdata = {}\n",
    "    psum_soup = BeautifulSoup(val, 'html.parser')\n",
    "    psumhostdata = psum_soup.find('div', attrs={'id': 'dsummary'}).find('table')\n",
    "    psumheadvals = psumhostdata.findAll('th')\n",
    "    psumvals = psumhostdata.findAll('td')\n",
    "    for ps in psumheadvals:\n",
    "        psumHeads.append(ps.text.replace(\" \", \"\"))\n",
    "    for count, psval in enumerate(psumvals):\n",
    "        psumdata[psumHeads[count]]=cleanSpecialChar(psval.text)              \n",
    "    psumVals.append(psumdata)\n",
    "    summary['ProjectSummary']=psumVals\n",
    "    \n",
    "        \n",
    "# #     processing budget part\n",
    "    budgetHeads = []\n",
    "    budgetVals = []\n",
    "    budgetdata = {}\n",
    "    soup = BeautifulSoup(val, 'html.parser')\n",
    "    hostdata = soup.find('div', attrs={'id': 'p_budget'}).find('div').find('table')\n",
    "    headvals = hostdata.findAll('th')\n",
    "    vals = hostdata.findAll('td')\n",
    "    for h in headvals:\n",
    "        budgetHeads.append(h.text.replace(\" \", \"\"))\n",
    "    for count, d in enumerate(vals):\n",
    "        if count != 6:\n",
    "            budgetdata[budgetHeads[count]]=d.text\n",
    "    budgetVals.append(budgetdata)\n",
    "    summary['Budget']=budgetVals\n",
    "    \n",
    "    \n",
    "# #     processing beneficiary part\n",
    "    beneficiaryHeads = ['No', 'Village', 'BeneficiaryTotal', 'BeneficiaryWomen', 'Households']\n",
    "    raw_head = []\n",
    "    beneficiaryVals = []\n",
    "    beneficiarydata = {}\n",
    "    benehost = {}\n",
    "    bene_soup = BeautifulSoup(val, 'html.parser')\n",
    "    hostbenedata = bene_soup.find('div', attrs={'id': 'p_beneficary'}).find('div').find('table')\n",
    "    beneheadvals = hostbenedata.findAll('th')\n",
    "    benevals = hostbenedata.findAll('td')\n",
    "    for h in beneheadvals:\n",
    "        raw_head.append(h.text.replace(\" \", \"\"))\n",
    "    for bene_count, bene_d in enumerate(benevals):\n",
    "        if bene_count < 5:\n",
    "            beneficiarydata[beneficiaryHeads[bene_count]]=cleanSpecialCharAndSpace(bene_d.text)\n",
    "    beneficiaryVals.append(beneficiarydata)\n",
    "    summary['Beneficiary']=beneficiaryVals\n",
    "\n",
    "\n",
    "# # processing output part\n",
    "    outputHeads = []\n",
    "    outputVals = []\n",
    "    outputdata = {}\n",
    "    outputhost = {}\n",
    "    output_soup = BeautifulSoup(val, 'html.parser')\n",
    "    outputhostdata = output_soup.find('div', attrs={'id': 'p_outputs'}).find('div').find('table')\n",
    "    outputheadvals = outputhostdata.findAll('th')\n",
    "    outputvals = outputhostdata.findAll('td')\n",
    "    for h in outputheadvals:\n",
    "        outputHeads.append(h.text.replace(\" \", \"\"))\n",
    "    for out_count, out_val in enumerate(outputvals):\n",
    "        if out_count < 6:\n",
    "            outputdata[outputHeads[out_count]]=cleanSpecialChar(out_val.text)\n",
    "    outputVals.append(outputdata)\n",
    "    summary['Outputs_Estimated_Cost']=outputVals\n",
    "\n",
    "\n",
    "# # processing technical part\n",
    "    tech_soup = BeautifulSoup(val, 'html.parser')\n",
    "    tech_main_data = tech_soup.find('div', attrs={'id': 'p_clearance'})\n",
    "    techform = {}\n",
    "    \n",
    "#   Evironmental safeguard clearance \n",
    "    envHeads = []\n",
    "    envVals = []\n",
    "    envdata = {}\n",
    "    envhost = {}\n",
    "    tech_env_data = tech_main_data.find('div', attrs={'id' : 'divEA'})\n",
    "    envheadvals = tech_env_data.findAll('th')\n",
    "    envvals = tech_env_data.findAll('td')\n",
    "    for e in envheadvals:\n",
    "        envHeads.append(e.text.replace(\" \", \"\"))\n",
    "    for e_count, e_val in enumerate(envvals):\n",
    "        envdata[envHeads[e_count]]=cleanSpecialChar(e_val.text)\n",
    "    envVals.append(envdata)\n",
    "    techform['Evironmental_Safeguard']=envVals\n",
    "    \n",
    "#   Land safeguard clearance\n",
    "    landHeads = []\n",
    "    landVals = []\n",
    "    landdata = {}\n",
    "    landhost = {}\n",
    "    tech_land_data = tech_main_data.find('div', attrs={'id' : 'divLAR'})\n",
    "    landheadvals = tech_land_data.findAll('th')\n",
    "    landvals = tech_land_data.findAll('td')\n",
    "    for l in landheadvals:\n",
    "        landHeads.append(l.text.replace(\" \", \"\"))\n",
    "    for l_count, l_val in enumerate(landvals):\n",
    "        landdata[landHeads[l_count]]=cleanSpecialChar(l_val.text)\n",
    "    landVals.append(landdata)\n",
    "    techform['Land_Safeguard']=landVals\n",
    "    \n",
    "#   Highland people safeguard clearance   \n",
    "    highHeads = []\n",
    "    highVals = []\n",
    "    highdata = {}\n",
    "    highhost = {}\n",
    "    tech_highland_data = tech_main_data.find('div', attrs={'id' : 'divHP'})\n",
    "    highheadvals = tech_highland_data.findAll('th')\n",
    "    highvals = tech_highland_data.findAll('td')\n",
    "    for h in highheadvals:\n",
    "        highHeads.append(h.text.replace(\" \", \"\"))\n",
    "    for h_count, h_val in enumerate(highvals):\n",
    "        highdata[highHeads[h_count]]=cleanSpecialChar(h_val.text)\n",
    "    highVals.append(highdata)\n",
    "    techform['Highland_Safeguard']=highVals\n",
    "    \n",
    "#   Sign-Off\n",
    "    signHeads = []\n",
    "    signVals = []\n",
    "    signdata = {}\n",
    "    signhost = {}\n",
    "    tech_signoff_data = tech_main_data.find('div', attrs={'id' : 'pSignOff'})\n",
    "    signheadvals = tech_signoff_data.findAll('th')\n",
    "    signvals = tech_signoff_data.findAll('td')\n",
    "    for s in signheadvals:\n",
    "        signHeads.append(s.text.replace(\" \", \"\"))\n",
    "    for s_count, s_val in enumerate(signvals):\n",
    "        signdata[signHeads[s_count]]=cleanSpecialChar(s_val.text)\n",
    "    signVals.append(signdata)\n",
    "    techform['Signoff']=signVals\n",
    "    summary['Technical_Clearance']=techform\n",
    "    \n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intended-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting contract_html to json objects\n",
    "def getCHTML(val, idval):\n",
    "    contract_summary = {}\n",
    "    \n",
    "# #     inserting id value to contract summary\n",
    "    contract_summary['Id']=idval\n",
    "    \n",
    "# #     processing contract summary information\n",
    "    csumHeads = []\n",
    "    csumVals = []\n",
    "    csumdata = {}\n",
    "    csum_soup = BeautifulSoup(val, 'html.parser')\n",
    "    csumhostdata = csum_soup.find('div', attrs={'id': 'dhead'}).find_all('table')\n",
    "    try: \n",
    "        csumheadvals = csumhostdata[0].findAll('th')\n",
    "        csumvals = csumhostdata[0].findAll('td')\n",
    "        csumheadonevals = csumhostdata[1].findAll('th')\n",
    "        csumonevals = csumhostdata[1].findAll('td')\n",
    "        for cs in csumheadvals:\n",
    "            csumHeads.append(cs.text.replace(\" \", \"\"))\n",
    "        for cso in csumheadonevals:\n",
    "            csumHeads.append(cso.text.replace(\" \", \"\"))\n",
    "        for csov in csumonevals:\n",
    "            csumvals.append(csov)\n",
    "        for count, csval in enumerate(csumvals):\n",
    "            csumdata[csumHeads[count]]=cleanSpecialChar(csval.text) \n",
    "    except: \n",
    "        print('failed to get contract summary')\n",
    "             \n",
    "    csumVals.append(csumdata)\n",
    "    contract_summary['ContractSummary']=csumVals\n",
    "\n",
    "\n",
    "    \n",
    "# #     processing budget part\n",
    "    budgetHeads = []\n",
    "    budgetVals = []\n",
    "    rawVals = []\n",
    "    rawbvals = []\n",
    "    budgetdata = {}\n",
    "    soup = BeautifulSoup(val, 'html.parser')\n",
    "    hostdata = soup.find('div', attrs={'id': 'dbudget'}).find('table')\n",
    "    budgetheadvals = hostdata.findAll('th')\n",
    "    budgetvals = hostdata.findAll('td')\n",
    "    for h in budgetheadvals:\n",
    "        budgetHeads.append(h.text.replace(\" \", \"\"))\n",
    "    for budget_count, budget_val in enumerate(budgetvals):\n",
    "        rawbvals.append(cleanSpecialChar(budget_val.text))\n",
    "    for bvc in range(int(len(rawbvals)/2)):\n",
    "        bvcval = bvc+1\n",
    "        btdval = soup.find('div', attrs={'id': 'dbudget'}).find('table').find('tr', attrs={'id': 'row_cb_'+str(bvcval)+''}).findAll('td')\n",
    "        bvform = {}\n",
    "        for c, td in enumerate(btdval):\n",
    "            bvform[budgetHeads[c]]=td.text\n",
    "        budgetVals.append(bvform)\n",
    "    contract_summary['Budget']=budgetVals\n",
    "    \n",
    "    \n",
    "# #     processing bidding part\n",
    "    biddingHeads = [\"No\"]\n",
    "    raw_head = []\n",
    "    bidVals = []\n",
    "    biddata = {}\n",
    "    bidhost = {}\n",
    "    rawdatalist = []\n",
    "    bid_soup = BeautifulSoup(val, 'html.parser')\n",
    "    hostbiddata = bid_soup.find('div', attrs={'id': 'dlbid'}).find('table')\n",
    "    bidheadvals = hostbiddata.findAll('th')\n",
    "    bidvals = hostbiddata.findAll('td')\n",
    "    bidtrs = hostbiddata.find('tbody').findAll('tr')\n",
    "    for h in bidheadvals:\n",
    "        biddingHeads.append(h.text.replace(\" \", \"\"))\n",
    "    del biddingHeads[1]\n",
    "    del biddingHeads[-1]\n",
    "    for b_count, b_tr in enumerate(bidtrs):\n",
    "        numval = b_count+1\n",
    "        bidtdval = hostbiddata.find('tbody').find('tr', attrs={'id': 'tbbs_'+str(numval)+''}).findAll('td')\n",
    "        bidform = {}\n",
    "        for c, td in enumerate(bidtdval):\n",
    "            bidform[biddingHeads[c]]=cleanSpecialCharAndSpace(td.text)\n",
    "        bidVals.append(bidform)\n",
    "    contract_summary['Bidding']=bidVals\n",
    "\n",
    "\n",
    "\n",
    "# # processing output part\n",
    "    outputHeads = []\n",
    "    outputVals = []\n",
    "    outputdata = {}\n",
    "    outputhost = {}\n",
    "    output_soup = BeautifulSoup(val, 'html.parser')\n",
    "    outputhostdata = output_soup.find('div', attrs={'id': 'c_outputs'}).find('div').find('table')\n",
    "    outputheadvals = outputhostdata.findAll('th')\n",
    "    outputvals = outputhostdata.findAll('td')\n",
    "    for h in outputheadvals:\n",
    "        outputHeads.append(h.text.replace(\" \", \"\"))\n",
    "    for out_count, out_val in enumerate(outputvals):\n",
    "        if out_count < 9:\n",
    "            outputdata[outputHeads[out_count]]=cleanSpecialChar(out_val.text)\n",
    "        else:\n",
    "            outputdata[outputHeads[-2]]=outputHeads[-1]\n",
    "        outputdata[outputHeads[-2]]=outputHeads[-1]\n",
    "    outputVals.append(outputdata)\n",
    "    print(\"\\n\")\n",
    "    contract_summary['Outputs_Actual_Cost']=outputVals\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# # processing progress part\n",
    "    pureprogressVals = []\n",
    "# # processing progress/work part\n",
    "    workHeads = []\n",
    "    workVals = []\n",
    "    rawwvals = []\n",
    "    workdata = {}\n",
    "    workhost = {}\n",
    "    work_soup = BeautifulSoup(val, 'html.parser')\n",
    "    workhostdata = work_soup.find('div', attrs={'id': 'd_actual_work'}).find('table')\n",
    "    workheadvals = workhostdata.findAll('th')\n",
    "    workvals = workhostdata.findAll('td')\n",
    "    for h in workheadvals:\n",
    "        workHeads.append(h.text.replace(\" \", \"\"))\n",
    "    for work_count, work_val in enumerate(workvals):\n",
    "        rawwvals.append(cleanSpecialChar(work_val.text))\n",
    "    workdata[workHeads[0]]=cleanSpecialChar(rawwvals[0])\n",
    "    workdata[workHeads[1]]=cleanSpecialChar(rawwvals[1])\n",
    "    try:\n",
    "        workdata['ActualworkstartdateDescription']=cleanSpecialChar(rawwvals[2])\n",
    "        workdata['ActualworkcompletiondateDescription']=cleanSpecialChar(rawwvals[3])\n",
    "    except:\n",
    "        print(\"\")\n",
    "    pureprogressVals.append(workdata)\n",
    "\n",
    "\n",
    "# # processing progress/progress part\n",
    "    progressHeads = []\n",
    "    progressVals = []\n",
    "    rawpvals = []\n",
    "    progressdata = {}\n",
    "    progresshost = {}\n",
    "    progress_soup = BeautifulSoup(val, 'html.parser')\n",
    "    progresshostdata = progress_soup.find('div', attrs={'id': 'dlprogress'}).find('table')\n",
    "    progressheadvals = progresshostdata.findAll('th')\n",
    "    progressvals = progresshostdata.findAll('td')\n",
    "    for h in progressheadvals:\n",
    "        progressHeads.append(h.text.replace(\" \", \"\"))\n",
    "    for progress_count, progress_val in enumerate(progressvals):\n",
    "        rawpvals.append(cleanSpecialChar(progress_val.text))\n",
    "    for pvc in range(int(len(rawpvals)/4)):\n",
    "        pvcval = pvc+1\n",
    "        ptdval = progress_soup.find('div', attrs={'id': 'dlprogress'}).find('table').find('tr', attrs={'id': 'row_cp_'+str(pvcval)+''}).findAll('td')\n",
    "        pvform = {}\n",
    "        for c, td in enumerate(ptdval):\n",
    "            pvform[progressHeads[c]]=td.text\n",
    "        progressVals.append(pvform)\n",
    "    pureprogressVals.append(progressVals)\n",
    "    contract_summary['progress']=pureprogressVals\n",
    "    \n",
    "        \n",
    "# #     processing payment part\n",
    "    paymentHeads = []\n",
    "    raw_head = []\n",
    "    paymentVals = []\n",
    "    paymentdata = {}\n",
    "    payhost = {}\n",
    "    pform = {}\n",
    "    pay_soup = BeautifulSoup(val, 'html.parser')\n",
    "    hostpaydata = pay_soup.find('div', attrs={'id': 'c_payment'}).find('div').find('table')\n",
    "    payheadvals = hostpaydata.findAll('th')\n",
    "    payvals = hostpaydata.find('tr').findAll('tr')\n",
    "    for h in payheadvals:\n",
    "        paymentHeads.append(h.text.replace(\" \", \"\"))\n",
    "    payvals.pop()\n",
    "    payvals.pop()\n",
    "    payvals.pop()\n",
    "    for pay_count, pay_d in enumerate(payvals):\n",
    "        rawpvalso = []\n",
    "        rawpvals = []\n",
    "        rawpformat = {}\n",
    "        rawpvals.append(rawpformat)\n",
    "        rawpvalso.append(pay_d.text.replace(\" \", \"\"))\n",
    "        respval = rawpvalso[0].replace(\",\", \"\").replace(\"\\n\", \",\")\n",
    "        resphost = respval.split(\",\")\n",
    "        del resphost[0]\n",
    "        resphost.pop()\n",
    "        for p_count, p_v in enumerate(resphost):\n",
    "            rawpformat[paymentHeads[p_count]]=cleanSpecialCharAndSpace(p_v)\n",
    "        paymentVals.append(rawpformat)            \n",
    "    pform[paymentHeads[-11]+\"Gross\"]=cleanSpecialCharAndSpace(paymentHeads[-10])\n",
    "    pform['ActualPaymentCumulativeToDate(A)Net']=cleanSpecialCharAndSpace(paymentHeads[-9])\n",
    "    pform['ActualPaymentCumulativeToDate(A)Tax']=cleanSpecialCharAndSpace(paymentHeads[-8])\n",
    "    pform[paymentHeads[-6]+\"Gross\"]=cleanSpecialCharAndSpace(paymentHeads[-5])\n",
    "    hostpaytext = pay_soup.find('div', attrs={'id': 'c_payment'}).findAll('p')\n",
    "    if hostpaytext is not None:\n",
    "        pform['TaxDescription']= hostpaytext[1].text\n",
    "    paymentVals.append(pform)\n",
    "    contract_summary['payment']=paymentVals\n",
    "    \n",
    "    \n",
    "    return contract_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interpreted-possession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "failed to get contract summary\n",
      "\n",
      "\n",
      "failed to get contract summary\n",
      "\n",
      "\n",
      "failed to get contract summary\n",
      "\n",
      "\n",
      "failed to get contract summary\n",
      "\n",
      "\n",
      "failed to get contract summary\n",
      "\n",
      "\n",
      "failed to get contract summary\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    for j in host[i]['projects']:\n",
    "        pidval = splitPID(j['project_link'])\n",
    "        idval = splitPID(j['contract_link'])\n",
    "        single_p_summary=getPHTML(j['project_html'], pidval)\n",
    "        single_c_summary=getCHTML(j['contract_html'], idval)\n",
    "        hostList.append(single_p_summary)\n",
    "        chostList.append(single_c_summary)\n",
    "    write_data(hostList, \"project_detail_list.json\")\n",
    "    write_data(chostList, \"contract_detail_list.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "partial-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pidMatcher(val):\n",
    "    for i in hostList:\n",
    "        if len(i) != 0 and i['Pid'] is not None:\n",
    "            if i['Pid'] == val:\n",
    "                return i\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "numerical-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idMatcher(val):\n",
    "    for i in chostList:\n",
    "        if len(i) != 0 and i['Id'] is not None:  \n",
    "            if i['Id'] == val:\n",
    "                return i\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "collected-oakland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LinkinHost\n",
      "\n",
      "\n",
      "\n",
      "{'project_name': 'Mixed gravel road', 'project_link': '/pid/project/home/view.castle?pid=177665e9-776e-4446-91a9-9c9200a1553c', 'contract_id': '010201/09/01-01', 'contract_link': '/pid/contract/home/view.castle?id=010201090101', 'project_data': {'Pid': '177665e9-776e-4446-91a9-9c9200a1553c', 'ProjectSummary': [{'Location': '[ 10201 ] Banteay Meanchey \\\\ Mongkol Borei \\\\ Banteay Neang', 'Sector': 'Economic', 'Sub-Sector': 'Rural Transport', 'TechnicalAssistant': 'Pen Phal', 'NatureofProject': 'Infrastructure', 'Name': 'Mixed gravel road', 'Objective': 'It is easy to travel and transport all kind of crops.', 'Relatedcontract(s)': '010201/09/01-01 ', 'CreatedBy': 'Chhun Sophal', 'Mobile': '012 921 850'}], 'Budget': [{'CalendarYear': '2009', 'NationalTransfer*': '72,669,000', 'LocalRevenue': '0', 'CarryOver': '0', 'Other': '0', 'Total': '72,669,000'}], 'Beneficiary': [{'No': '1', 'Village': 'Trabaek', 'BeneficiaryTotal': '530', 'BeneficiaryWomen': '281', 'Households': '106'}], 'Outputs_Estimated_Cost': [{'Nr.': '1', 'Village': 'Khilek', 'Description': 'Crushed stone road Upgrade [ 1010105 ]Dimension #1 : 4.000 Width (m)Dimension #2 : 1,192.000 Volume of earth (m3)', 'Qty': '1.410 km', 'UnitCost': '45,844,686', 'Total': '64,641,007'}], 'Technical_Clearance': {'Evironmental_Safeguard': [{'Impact': 'This project did not require environment study.', 'Reason': 'The project is implemented on the old road.'}], 'Land_Safeguard': [{'Impact': 'This project did not require land acquisition report.Public', 'Reason': 'The project is implemented on the old road.'}], 'Highland_Safeguard': [{'Impact': 'This project did not require highland people report.', 'Reason': 'There have no aborigines lived at that project location.'}], 'Signoff': [{'Feasibilitystudycompletedon': '12-Apr-2009', 'Technicalclearancesign-off': '07-May-2009'}]}}, 'contract_data': {'Id': '010201090101', 'ContractSummary': [{'AreaName': '[ 10201 ] Banteay Meanchey \\\\ Mongkol Borei \\\\ Banteay Neang', 'Contract': '010201/09/01-01( 1 )', 'TechnicalSupervisor': 'Pen Phal', \"Project'sName\": 'Mixed gravel road', 'Sector': 'Economic', 'Sub-Sector': 'Rural Transport', 'Contractor': 'Lao Bunna, [ Mr. Seth Hoeum ]', 'Competitivebidding': 'Yes ( 01-Jul-2009 )', 'Numberofcontractor': '6', 'Contractsigndate(Form50)': '08-Jul-2009', 'Guaranteeperiod': '6 Month', 'Plannedworkstartdate': '25-Jul-2009', 'Plannedworkcompletiondate': '25-Sep-2009', 'CreatedBy': 'Chhun Sophal', 'Mobile': '012 921 850', 'RILGPStatus': 'Eligible', 'Confirmation': '06-Jan-2010', 'Closeddateon': '31-Mar-2010'}], 'Budget': [{'FundSource': 'Commune/Sangkat Fund', 'Cost': '70,719,120'}, {'FundSource': 'Local Contribution', 'Cost': '1,000,000'}], 'Bidding': [{'No': '1', \"Director'sName\": 'Mr.SethHoeum', 'Contractor': 'LaoBunna', 'BidValue': '61,400,000R', 'DiscountRate': '-5%', 'Rejected': 'No', 'Reason': ''}, {'No': '2', \"Director'sName\": 'Mrs.ChavYinh', 'Contractor': 'TangSamnang', 'BidValue': '63,348,186R', 'DiscountRate': '-2%', 'Rejected': 'No', 'Reason': ''}, {'No': '3', \"Director'sName\": 'Mr.SoeungSeu', 'Contractor': 'SoeungSeu', 'BidValue': '63,994,597R', 'DiscountRate': '-1%', 'Rejected': 'No', 'Reason': ''}, {'No': '4', \"Director'sName\": 'Mr.SemKhemra', 'Contractor': 'SemMoun', 'BidValue': '62,471,163R', 'DiscountRate': '-3%', 'Rejected': 'No', 'Reason': ''}, {'No': '5', \"Director'sName\": 'Mr.SarSong', 'Contractor': 'SarSong', 'BidValue': '62,701,776R', 'DiscountRate': '-3%', 'Rejected': 'No', 'Reason': ''}, {'No': '6', \"Director'sName\": 'Mr.SroeunSokha', 'Contractor': 'PrakSarak', 'BidValue': '63,450,000R', 'DiscountRate': '-2%', 'Rejected': 'No', 'Reason': ''}], 'Outputs_Actual_Cost': [{'Nr.': '1', 'Totalcontractcostincludetax': '71,719,120', 'Village': 'Khilek', 'Description': '[ 1010105 ] Crushed stone road UpgradeDimension #1 : 4.000 Width (m)Dimension #2 : 1,351.000 Volume of earth (m3)', 'Bid': '1.410 km', 'InContract': '1.599 km', 'Actualquantity': '1.599 km', 'UnitCost/Estimated': '43,546,100est. 45,844,686', 'DiscountRate': '-5 %', 'Total': '69,630,214'}], 'progress': [{'Actualworkstartdate': '25-Jul-2009', 'Actualworkcompletiondate': '25-Sep-2009', 'ActualworkstartdateDescription': 'PIM 3.13.1 start of work meeting date', 'ActualworkcompletiondateDescription': 'PIM 3.13.7 section A/B 80% payment approval date.'}, [{'Date': '22-Aug-2009', 'Progress': '50 %', 'ReportBy': 'Ly Heng', 'Note': ''}, {'Date': '25-Sep-2009', 'Progress': '100 %', 'ReportBy': 'Ly Heng', 'Note': ''}]], 'payment': [{'Date': '03-Sep-2009', 'Source': 'CSF', 'Description': '1stPayment', 'Gross': '28687600R', 'Net': '27826972R', 'Tax': '860628R', 'Verified': 'HouSophyra'}, {'Date': '29-Sep-2009', 'Source': 'CSF', 'Description': '2ndPayment', 'Gross': '27687600R', 'Net': '26856972R', 'Tax': '830628R', 'Verified': 'HouSophyra'}, {'Date': '29-Sep-2009', 'Source': 'LC', 'Description': '2ndPayment', 'Gross': '1000000R', 'Net': '970000R', 'Tax': '30000R', 'Verified': 'HouSophyra'}, {'Date': '06-Apr-2010', 'Source': 'CSF', 'Description': 'Finalpayment', 'Gross': '14343920R', 'Net': '13976270R', 'Tax': '367650R', 'Verified': 'SothChhengLen'}, {'ActualPaymentCumulativeToDate(A)Gross': '71,719,120R', 'ActualPaymentCumulativeToDate(A)Net': '69,630,214R', 'ActualPaymentCumulativeToDate(A)Tax': '2,088,906R', 'ContractValue(B)Gross': '71,719,120R', 'TaxDescription': 'Tax Deduction Rate: 3 %'}]}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'project_name': 'Laterite  road', 'project_link': '/pid/project/home/view.castle?pid=422cdb97-57fc-4106-ac95-9dfb00ae0eb3', 'contract_id': '010201/10/01-01', 'contract_link': '/pid/contract/home/view.castle?id=010201100101'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'project_name': 'Not yet translate', 'project_link': '/pid/project/home/view.castle?pid=9c18aa8e-d82a-4ce6-8464-9f3c00f7c548', 'contract_id': '010201/11/01-01', 'contract_link': '/pid/contract/home/view.castle?id=010201110101'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'project_name': 'Not yet translate', 'project_link': '/pid/project/home/view.castle?pid=2f920493-a785-4542-9bbf-a08400b37980', 'contract_id': '010201/12/01-01', 'contract_link': '/pid/contract/home/view.castle?id=010201120101'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'project_name': '', 'project_link': '/pid/project/home/view.castle?pid=00b15c39-4531-4b23-a9b5-a20500e0bd07', 'contract_id': '010201/13/01-01', 'contract_link': '/pid/contract/home/view.castle?id=010201130101'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'project_name': '', 'project_link': '/pid/project/home/view.castle?pid=d38d3853-63f0-4c44-bc7b-a38c0122aca3', 'contract_id': '010201/14/01-01', 'contract_link': '/pid/contract/home/view.castle?id=010201140101'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'project_name': 'unlined earth canal', 'project_link': '/pid/project/home/view.castle?pid=38a55de8-6871-455c-945b-a5fe00b1fa85', 'contract_id': '010201/15/01-01', 'contract_link': '/pid/contract/home/view.castle?id=010201150101'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'project_name': 'canal restoration', 'project_link': '/pid/project/home/view.castle?pid=f979cb45-4366-471b-ab5d-a6e300a54ec5', 'contract_id': '010201/16/01-01', 'contract_link': '/pid/contract/home/view.castle?id=010201160101'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'project_name': 'Laterite road', 'project_link': '/pid/project/home/view.castle?pid=3c05a066-e656-4c44-b365-a9bb00f75111', 'contract_id': '010201/17/01-01', 'contract_link': '/pid/contract/home/view.castle?id=010201170101'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'project_name': 'Laterite road', 'project_link': '/pid/project/home/view.castle?pid=14d23ba0-a9c8-4a5a-8285-aa6000b7e206', 'contract_id': '010201/18/01-01', 'contract_link': '/pid/contract/home/view.castle?id=010201180101'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'project_name': '', 'project_link': '/pid/project/home/view.castle?pid=b3d4bfb6-fde1-4a0a-a84d-ab9700a09a8d', 'contract_id': '010201/19/02-01', 'contract_link': '/pid/contract/home/view.castle?id=010201190201'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'project_name': 'Earth Road', 'project_link': '/pid/project/home/view.castle?pid=12bc7239-6ec3-4b99-ae64-abb500f1347d', 'contract_id': '010201/19/01-01', 'contract_link': '/pid/contract/home/view.castle?id=010201190101'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    lhost = {}\n",
    "    pjlist = []\n",
    "    lhost['location']=linkinghost[i]['location']\n",
    "    print(\"\\nLinkinHost\\n\")\n",
    "    for j in linkinghost[i]['projects']:\n",
    "        pidval = splitPID(j['project_link'])\n",
    "        idval = splitPID(j['contract_link'])\n",
    "        resp = pidMatcher(pidval)\n",
    "        resc = idMatcher(idval)\n",
    "        if resp is not None:\n",
    "            j['project_data']=resp\n",
    "        if resc is not None:\n",
    "            j['contract_data']=resc\n",
    "        pjlist.append(j)\n",
    "        print(\"\\n\")\n",
    "        print(j)\n",
    "        print(\"\\n\")\n",
    "    lhost['projects']=pjlist\n",
    "    write_data(lhost, \"final_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-airplane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-roots",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-sydney",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
